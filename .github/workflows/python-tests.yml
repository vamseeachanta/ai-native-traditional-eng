# Python Tests GitHub Actions Workflow
# Customized for ai-native-traditional-eng project

name: Python Tests

on:
  push:
    branches: [ main, develop ]
    paths:
      - '**/*.py'
      - 'requirements*.txt'
      - 'pyproject.toml'
      - 'uv.toml'
      - '.github/workflows/python-tests.yml'
  pull_request:
    branches: [ main, develop ]
    paths:
      - '**/*.py'
      - 'requirements*.txt'
      - 'pyproject.toml'
      - 'uv.toml'
  workflow_dispatch:
  schedule:
    # Run tests every Sunday at 2 AM UTC
    - cron: '0 2 * * 0'

env:
  # Global environment variables
  PYTHONUNBUFFERED: 1
  FORCE_COLOR: 1
  TESTING: true

jobs:
  test:
    name: Test on Python ${{ matrix.python-version }} (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    timeout-minutes: 30

    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.9', '3.10', '3.11', '3.12']
        os: [ubuntu-latest, windows-latest, macos-latest]
        # Exclude older Python on some OS to speed up CI
        exclude:
          - os: windows-latest
            python-version: '3.9'
          - os: macos-latest
            python-version: '3.9'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Install uv
      uses: astral-sh/setup-uv@v1
      with:
        version: "latest"

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Install system dependencies (Ubuntu)
      if: matrix.os == 'ubuntu-latest'
      run: |
        sudo apt-get update
        sudo apt-get install -y \
          libpq-dev \
          wkhtmltopdf \
          xvfb

    - name: Install dependencies with uv
      run: |
        uv pip install --system -r requirements-consolidated.txt
        uv pip install --system -e .

    - name: Install test dependencies
      run: |
        uv pip install --system \
          pytest>=7.0 \
          pytest-cov>=4.0 \
          pytest-mock>=3.0 \
          pytest-xdist>=3.0 \
          pytest-timeout>=2.0 \
          bandit>=1.7 \
          psutil>=5.0

    - name: Lint with ruff (already installed)
      run: |
        ruff check src/ tests/ --output-format=github
        ruff format --check src/ tests/

    - name: Type checking with mypy (if available)
      run: |
        if command -v mypy &> /dev/null; then
          mypy src/ --ignore-missing-imports --check-untyped-defs
        else
          echo "mypy not installed, skipping type checking"
        fi
      continue-on-error: true

    - name: Security check with bandit
      run: |
        bandit -r src/ -f json -o bandit-report.json || true
        if [ -f bandit-report.json ]; then
          echo "Bandit security scan completed"
          cat bandit-report.json
        fi
      continue-on-error: true

    - name: Run tests with pytest
      run: |
        pytest \
          --cov=src \
          --cov-report=xml \
          --cov-report=html \
          --cov-report=term-missing \
          --cov-fail-under=70 \
          --junitxml=pytest.xml \
          --verbose \
          --timeout=300 \
          -n auto
      env:
        # Environment variables for testing
        TESTING: true

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      if: matrix.python-version == '3.11' && matrix.os == 'ubuntu-latest'
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false

    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: test-results-${{ matrix.python-version }}-${{ matrix.os }}
        path: |
          pytest.xml
          htmlcov/
          bandit-report.json
        retention-days: 30

    - name: Upload coverage reports
      uses: actions/upload-artifact@v3
      if: matrix.python-version == '3.11' && matrix.os == 'ubuntu-latest'
      with:
        name: coverage-report
        path: |
          coverage.xml
          htmlcov/
        retention-days: 30

  smoke-tests:
    name: Smoke Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Install uv
      uses: astral-sh/setup-uv@v1
      with:
        version: "latest"

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: 3.11

    - name: Install minimal dependencies
      run: |
        uv pip install --system pytest loguru
        uv pip install --system -e .

    - name: Run smoke tests only
      run: |
        pytest tests/test_smoke.py \
          --verbose \
          -m "not slow" \
          --timeout=60

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: smoke-tests
    timeout-minutes: 45
    if: github.event_name != 'schedule'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Install uv
      uses: astral-sh/setup-uv@v1
      with:
        version: "latest"

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: 3.11

    - name: Install dependencies
      run: |
        uv pip install --system -r requirements-consolidated.txt
        uv pip install --system pytest pytest-cov pytest-mock
        uv pip install --system -e .

    - name: Run integration tests
      run: |
        pytest tests/integration/ \
          --cov=src \
          --cov-report=xml \
          --verbose \
          -m "integration" \
          --timeout=600
      env:
        TESTING: true

  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: test
    timeout-minutes: 20
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Install uv
      uses: astral-sh/setup-uv@v1
      with:
        version: "latest"

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: 3.11

    - name: Install dependencies
      run: |
        uv pip install --system -r requirements-consolidated.txt
        uv pip install --system pytest pytest-benchmark psutil
        uv pip install --system -e .

    - name: Run performance tests
      run: |
        pytest tests/ \
          -m "slow" \
          --benchmark-only \
          --benchmark-json=benchmark.json \
          --verbose
      continue-on-error: true

    - name: Upload benchmark results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: benchmark-results
        path: benchmark.json
        retention-days: 90

  quality-gate:
    name: Quality Gate
    runs-on: ubuntu-latest
    needs: [test, smoke-tests, integration-tests]
    if: always()

    steps:
    - name: Check test results
      run: |
        echo "Checking test results..."

        if [[ "${{ needs.test.result }}" != "success" ]]; then
          echo "‚ùå Unit tests failed"
          exit 1
        fi

        if [[ "${{ needs.smoke-tests.result }}" != "success" ]]; then
          echo "‚ùå Smoke tests failed"
          exit 1
        fi

        # Integration tests are allowed to be skipped
        if [[ "${{ needs.integration-tests.result }}" == "failure" ]]; then
          echo "‚ö†Ô∏è  Integration tests failed"
          exit 1
        fi

        echo "‚úÖ All critical tests passed"

    - name: Quality gate passed
      run: echo "üéâ Quality gate passed! Ready for deployment."